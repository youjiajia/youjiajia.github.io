<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>docker常用命令</title>
      <link href="/docker_common_commands.html"/>
      <url>/docker_common_commands.html</url>
      <content type="html"><![CDATA[<h1 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h1><p>Docker就是，以docker容器为资源分割和调度的基本单位，封装整个软件运行时环境，为开发者和系统管理员设计的，用于构建、发布和运行分布式应用的平台。</p><p>docker的特性是易用，跨平台，可移植性。优势在于简化CI（持续集成）和CD（持续交互）的构建流程，让开发者集中精力在应用开发上。docker命令繁杂，本篇记录了docker常用的命令。</p><h1 id="Docker常用命令"><a href="#Docker常用命令" class="headerlink" title="Docker常用命令"></a>Docker常用命令</h1><ol><li>docker 环境信息<ul><li>docker info用于检查docker是否正确安装，一般结合docker version使用</li></ul></li><li><p>容器生命周期管理,涉及容器启动，停止等功能，常用的有run，start,stop,restart</p><ul><li><p>docker run命令用于基于特定的镜像创建一个容器，并依据选项控制容器。</p><ul><li>-i选项表示使用交互模式，始终保持输入流开放</li><li>-t选项表示分配一个伪终端，一般两个参数结合使用-it, 即可在终端中打开伪终端进行交互操作</li><li>–name选项可指定docker run命令启动的容器的名字。否则，docker将为容器随机分配一个名字</li><li>-c选项用于给运行在容器中的所有进程分配cpu的share值，这是一个相对权重，实际的处理速度还是与宿主机的cpu有关</li><li>-m选项 用于限制为容器中所有进程分配的内存总量，以B,K,M,G为单位</li><li>-v选项 用于挂载一个volume， 可以用一个-v参数挂载多个volume volume的格式为[host-dir]:[container-dir]:<a href="即宿主机文件/目录:容器里对应的文件/目录，rw为可读写，ro为只可读">rw:ro</a></li><li>-p选项用于将容器的端口暴露给宿主机的端口，其常用格式为hostPort:containerPort</li><li>-e或者-env设置环境变量</li><li>–link [name:aliasname]连接名为name的容器，并起一个别名为aliasname, 使用link不仅可以避免ip和端口暴露在外网的风险，还可以预防容器在重启后ip地址变化导致的访问失败，原理类似于dns的域名和地址映射。</li></ul></li><li><p>docker start/stop/restart命令用于对已存在的容器进去启动，停止和重启，一般使用容器id作标识，也可使用容器名来确定容器.start命令使用-i选项来开启交互模式，始终保持输入流开放。使用-a附加标准输入、输出和错误输出。此外，docker stop和docker restart命令使用-t选项来设定容器停止前的等待时间。</p></li></ul></li><li>docker registry<ul><li>docker pull命令从registry中拉取image或repository，使用方法为docker pull [options] name[:tag]，例如docker pull SEL/ubuntu:ubuntu12.04为从特定仓库拉取Ubuntu 12.04 tag的镜像</li><li>docker push命令将本地image或者repository推送到镜像库，使用方法如下: docker push NAME[:TAG]</li><li>docker commit 将一个容器固化为一个新的镜像，提交时只能选用正在运行的容器。</li></ul></li><li>镜像管理<ul><li>docker images列出主机镜像，默认只有顶层镜像，可以使用-a显示所有镜像</li><li>docker rmi删除镜像，可同时删除多个，但是删除镜像前必须先删除容器</li><li>docker rm删除容器,可同时删除多个</li><li>docker build构建镜像，-t指定最终镜像名称，后指定上下文路径，或Git repo或tar或从标准输入中读取</li></ul></li><li>运维操作<ul><li>docker attach连接到正在运行的容器，与主进程进行交互</li><li>docker inspect可以查看容器或镜像的详细信息</li><li>docker ps命令查看容器相关信息，默认只显示正在运行的容器,-a参数可以查看所有容器，-l参数可以查看最新的容器</li><li>docker events打印实时系统事件</li><li>docker history打印指定镜像历史版本信息</li><li>docker logs打印容器中进程的运行日志</li></ul></li></ol>]]></content>
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>fabric 服务器管理和应用发布神器</title>
      <link href="/about_fabric.html"/>
      <url>/about_fabric.html</url>
      <content type="html"><![CDATA[<h1 id="Fabric简介"><a href="#Fabric简介" class="headerlink" title="Fabric简介"></a>Fabric简介</h1><p>Fabric是一个Python的库和命令行工具,使用 Fabric 来执行 Python 函数或 task ，以实现与远程服务器的自动化交互, 提高基于ssh的应用部署和系统管理效率。</p><p>具体来说：</p><ul><li>可以通过命令行执行无参数python函数的工具</li><li>可以通过ssh更容易，更符合python风格的执行shell命令</li></ul><h1 id="STEP1-hello-wrold"><a href="#STEP1-hello-wrold" class="headerlink" title="STEP1: hello wrold"></a>STEP1: hello wrold</h1><p>使用pip安装fabric包，将以下代码写入fabfile.py文件中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def  hello （）：</span><br><span class="line">    print （“Hello world！” ）</span><br></pre></td></tr></table></figure><p>然后该hello函数即可作为fab工具，使用命令<code>fab hello</code>即可在命令行中打印出<code>hello world！</code></p><p>另外，和Python编程一样，给任务函数传递参数很有必要.Fabric支持Shell兼容的参数用法，让我们把代码改写一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def  hello (name = &quot;world&quot;):</span><br><span class="line">    print(&quot;Hello %s!&quot; % name)</span><br></pre></td></tr></table></figure><p>运行<code>fab hello:fabric</code>即可传入name=fabric参数，打印出<code>hello fabric！</code></p><h1 id="STEP2-运行本地和远程命令"><a href="#STEP2-运行本地和远程命令" class="headerlink" title="STEP2: 运行本地和远程命令"></a>STEP2: 运行本地和远程命令</h1><p>fabric使用local和run分别运行本地和远程命令，使用lcd和cd分别进行本地和远程的目录跳转。假设我们目前有一个django项目，我们希望进行如下自动化部署操作：</p><ul><li>运行<code>test my_app</code>进行自动化测试</li><li>使用git上传代码</li><li>在远程服务器更新代码</li></ul><p>我们将该操作分为两步，一步使用prepare_deploy进行本地代码的测试和上传，一步使用deploy进行远程代码的发布：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from fabric.api import local, settings, abort, run, cd, lcd</span><br><span class="line"></span><br><span class="line">def prepare_deploy():</span><br><span class="line">    code_dir = &apos;/srv/django/myproject&apos;</span><br><span class="line">    with lcd(code_dir):</span><br><span class="line">        local(&quot;./manage.py test my_app&quot;)</span><br><span class="line">        local(&quot;git add -p &amp;&amp; git commit&quot;)</span><br><span class="line">        local(&quot;git push&quot;)</span><br><span class="line"></span><br><span class="line">def deploy():</span><br><span class="line">    code_dir = &apos;/srv/django/myproject&apos;</span><br><span class="line">    with settings(warn_only=True):</span><br><span class="line">        if run(&quot;test -d %s&quot; % code_dir).failed:</span><br><span class="line">            run(&quot;git clone user@vcshost:/path/to/repo/.git %s&quot; % code_dir)</span><br><span class="line">    with cd(code_dir):</span><br><span class="line">        run(&quot;git pull&quot;)</span><br></pre></td></tr></table></figure><p>在deploy函数中，我们首先判断对应文件夹是否存在，不存在我们就将拉取代码。我们使用<code>with settings(warn_only=True)</code>将warn_only设置为true，该设置将代码中的error认为是警告来处理，以达到代码的灵活性。</p><p>将上述代码中的14行项目git库修改后，即可运行命令来完成操作，在运行<code>fab deploy</code>后需要输入连接远程的host string（如<a href="mailto:&#39;root@192.168.1.200" target="_blank" rel="noopener">&#39;root@192.168.1.200</a>‘），如果你的电脑与远程机器已经设置好ssh秘钥，则会直接连接成功，运行命令，否则需要输入密码。</p><p>运行结果如下:</p><p><img src="/images/fabric/ssh.png" alt="" title="描述"></p><h1 id="STEP3-其他有用配置"><a href="#STEP3-其他有用配置" class="headerlink" title="STEP3: 其他有用配置"></a>STEP3: 其他有用配置</h1><h3 id="环境字典env"><a href="#环境字典env" class="headerlink" title="环境字典env"></a>环境字典env</h3><p>如果我们有很多台服务器做负载均衡，我们不可能每台服务器都运行一次deploy，这时我们需要用到fabric的环境字典env</p><p>env下常用字典有user，roledefs和password字段，user字段用于设置连接远程的默认用户名，roledefs字段用于这时远程主机集群，passwords字段用于存储远程主机密码（如果你不想用ssh秘钥连接的话）。我们在fabric开头加入如下配置:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from fabric.api import local, settings, abort, run, cd, lcd， env</span><br><span class="line"></span><br><span class="line">env.user = &apos;root&apos;</span><br><span class="line"></span><br><span class="line">env.roledefs.update(&#123;</span><br><span class="line">&apos;test&apos;: [&apos;192.168.150.90&apos;],</span><br><span class="line">&apos;deploy&apos;: [</span><br><span class="line">&apos;192.168.141.113&apos;,</span><br><span class="line">&apos;192.168.133.102&apos;,</span><br><span class="line">&apos;192.168.129.150&apos;,</span><br><span class="line">&apos;192.168.100.199&apos;,</span><br><span class="line">]</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">env.passwords = &#123;</span><br><span class="line">&apos;root@192.168.150.90:22&apos;: &quot;root&quot;,</span><br><span class="line">&apos;root@192.168.141.113:22&apos;: &apos;root&apos;,</span><br><span class="line">&apos;root@192.168.133.102:22&apos;: &apos;root&apos;,</span><br><span class="line">&apos;root@192.168.129.150:22&apos;: &apos;root&apos;,</span><br><span class="line">&apos;root@192.168.100.199:22&apos;: &quot;root&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们配置了两个集群，分别为test测试服服务器和deploy正式服集群，配置登录用户名为root以及登录密码。</p><h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>fabric中提供了方便我们使用的装饰器，在配置完上述env后，我们可以为deploy加上role装饰器来制定对应集群.</p><p>对于一些可以并行执行的函数我们可以使用同时parallel装饰器来并行执行，或者对于一些不能并行执行的函数我们使用serial装饰器强制顺序执行（fabric默认顺序执行，如果修改 env.parallel可设置为并行执行，但是serial和parallel优先级更高）。</p><p>最后，我们可以使用task装饰器来装饰我们需要独立成任务的函数，使用task装饰器后，运行<code>fab --list</code>只有被该装饰器装饰的任务才会出现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from fabric.decorators import roles, parallel</span><br><span class="line">from fabric.api import env, task, hosts, execute, cd, prefix, runs_once, hide</span><br><span class="line">    ...</span><br><span class="line">@task</span><br><span class="line">@roles(&apos;deploy&apos;)</span><br><span class="line">def deploy():</span><br><span class="line">    code_dir = &apos;/srv/django/myproject&apos;</span><br><span class="line">    with settings(warn_only=True):</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h1 id="FINALL"><a href="#FINALL" class="headerlink" title="FINALL"></a>FINALL</h1><p>该教程只是简单介绍了fabric以及它的一些常用使用方法，配合python灵活运用可以极大的提升工作效率，如需要深入研究fabric可查看<a href="http://fabric-chs.readthedocs.io/zh_CN/chs/" target="_blank" rel="noopener">官方文档</a>。</p>]]></content>
      
      <categories>
          
          <category> 运维 </category>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> fabric </tag>
            
            <tag> python </tag>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>聊一聊微服务</title>
      <link href="/about_microservice.html"/>
      <url>/about_microservice.html</url>
      <content type="html"><![CDATA[<h1 id="什么是微服务？"><a href="#什么是微服务？" class="headerlink" title="什么是微服务？"></a>什么是微服务？</h1><blockquote><p>微服务现在受到了大量的关注︰ 文章、 博客、 社交媒体和学术会议上的讨论都能看到该词汇的身影。微服务正迅速走向所指的快速发展期。同时，软件社区的一些怀疑论者指出微服务并不是什么新鲜玩意儿。这些唱反调的人说微服务和SOA概念并没有什么不同，旧瓶装新酒而已，顺势炒炒新概念。然而，不管说是夸大也好，怀疑也罢，微服务架构模式应用在敏捷开发和交付复杂的企业应用程序的时候还是有巨大优势的。</p></blockquote><blockquote><p>一句话总结SOA和微服务的区别，即微服务不再强调传统SOA架构里面比较重的ESB企业服务总线，同时SOA思想进入单个业务系统内部实现真正的组件化。</p></blockquote><h1 id="微服务的核心思想"><a href="#微服务的核心思想" class="headerlink" title="微服务的核心思想"></a>微服务的核心思想</h1><p>微服务的基本思想在于考虑围绕业务领域组件来创建应用，这些应用可独立的进行开发、管理和加速。在分散的组件中使用微服务云架构和平台使部署、管理和服务功能交付变得更加简单。</p><p>微服务核心包括，其一足够构成一个独立小应用（从DB到UI），其二微服务应用之间只能通过ServiceAPI进行交互，其三一般运行在云虚拟机或更轻的docker容器上。微服务架构的重点就是业务系统需要彻底的组件化和服务化，原有的单个业务系统会拆分成多个可以独立开发，设计，运行和运维的小应用。这些小应用之间通过服务完成交互和集成。</p><p>对于微服务架构下首先仍然是要做好单个组件本身的持续集成，其次在这个基础上增加了多个组件的打包部署和组件间的集成。里面的核心思想就是Devops的思路，希望能够实现开发设计到运维部署的一体化。</p><h1 id="微服务的优势"><a href="#微服务的优势" class="headerlink" title="微服务的优势"></a>微服务的优势</h1><p>一个成功的应用总会随着时间逐步成长并变得巨大起来。每个敏捷Sprint周期，开发者会实现更多的功能，当然这就意味着又添加了很多行代码。时间长了后，当年写的小小的单体应用已经变成了巨大的单体怪物。而微服务则在这方面展现出他的优势：</p><ul><li>通过分解巨大单体应用为多个服务方法解决了复杂性问题。同时单个服务很容易开发，理解和维护。</li><li>这种架构使得每个服务都可以有专门开发团队来开发。开发者可以自由选择技术，提供API服务。</li><li>微服务架构使得每个微服务独立部署，开发者不再需要协调其他服务部署对本服务的影响</li><li>微服务架构模式使得每个服务独立扩展。</li></ul><p>微服务的目的是有效的拆分应用，实现敏捷开发和部署。和其他技术一样，微服务架构也有其劣势。</p><ul><li>微服务应用是分布式系统，由此会带来固有的复杂性，开发者需要在RPC或者消息传递之间选择并完成进程间的通讯机制。</li><li>分区的数据库架构，因为更新多个业务主体的事务很普遍。使用分布式事务并不一定是好的选择，不仅仅因为CAP理论，还因为当前高扩展性的nosql和消息传递中间件并不支持这一需求。最终不得不使用一个最终一致性的方法，从而对开发者提出了更高的要求和挑战。</li><li>部署和测试一个基于微服务架构的应用也是一个很复杂的任务</li><li>微服务架构模式应用的改变将会波及多个服务。</li></ul><h1 id="使用API网关构建微服务"><a href="#使用API网关构建微服务" class="headerlink" title="使用API网关构建微服务"></a>使用API网关构建微服务</h1><p>当我们选择把应用构建成一组微服务的时候，我们需要决定应用的客户端如何与这些微服务进行交互。</p><p>理论上客户端可以直接与每一个微服务进行通信，但是这种方案有诸多挑战和限制。</p><ol><li>客户端需求和每个微服务暴露的细粒度API不匹配。简单来说就是一个页面需要发送太多次的api请求，这种方法还使得客户端代码非常复杂。</li><li>部分服务协议对web并不友好</li><li>会使得微服务难以重构，比如未来想要合并，或拆分单个微服务非常困难。</li></ol><p>通常来说，API网关是更好的解决方式。API网关是个服务器，也可以说是进入系统的唯一节点。API网关封装内部系统的架构，并且提供API给各个客户端。它还可能具备授权，监控，负载均衡，缓存，请求分片和管理，静态响应处理等功能。因此，将API网关构建在一个支持异步，I/O非阻塞的平台是合理的。可用使用node.js。</p><p>对于API网关需要实现底层多个细粒度的API组合的场景，推荐采用响应式编程模型进行而不是传统的异步回调方法组合代码。其原因除了采用回调方式导致的代码混乱外，还有就是对于API组合本身可能存在并行或先后调用，对于采用回调方式往往很难控制。同时在实现API网关时，还需要处理局部失败的问题（服务响应慢或不可用的时候）。如果缓存数据可用，API网关还可以返回缓存数据。另外，API网关支持不同的通信机制，包括异步和同步两种类型的进程间通信机制，甚至还可能有同一类型的多种实现。</p><p>总结一下API网关的优缺点：</p><ul><li><p>最大的优点是，它封装了应用程序的内部结构。它和传统ESB的区别就是API网关更加轻量和高性能，他不需要考虑太多遗留系统和诸多协议的适配，其次也不需要考虑服务集成过程中的大量数据转换和映射。</p></li><li><p>缺点是它增加了一个我们必须开发、部署和维护的高可用组件。还有一点是，在我们期望的去中心化和全分布式架构中，API网关又变成了一个中心点或瓶颈点。</p></li></ul><h1 id="微服务中的服务发现"><a href="#微服务中的服务发现" class="headerlink" title="微服务中的服务发现"></a>微服务中的服务发现</h1><p>为了完成一次请求，代码需要知道服务实例的网络地址，对基于云端、现代化的微服务而言，服务实例的网络位置都是动态分配的，所以需要服务发现机制。服务发现分为客户端发现模式和服务端发现模式。</p><h2 id="客户端发现模式"><a href="#客户端发现模式" class="headerlink" title="客户端发现模式"></a>客户端发现模式</h2><p>客户端查询服务注册表（可用服务实例的数据库），用负载均衡算法选择一个实例，发出请求。即如何一个服务的消费都需要分成两个步骤进行，第一步访问服务注册库，第二步客户端与改服务建立连接。<br>缺点：底层ip暴露出来了，需要进一步做安全和防火墙隔离的场景下是不能用的。</p><h2 id="服务端发现模式"><a href="#服务端发现模式" class="headerlink" title="服务端发现模式"></a>服务端发现模式</h2><p>客户端通过负载均衡器向某个服务提出请求，负载均衡器查询注册表，并将请求转发到可用的服务实例。优点是客户端无需发现细节。缺点是负载均衡器是一个需要配置和管理的高可用系统组件。</p><p>服务注册表是服务发现的关键部分，它是一个包含服务实例网络地址的的数据库。一个服务注册表需要高可用和实时更新，客户端可以缓存从服务注册表获取的网络地址。必须多台部署（否则有单点故障），同时要考虑多台机器信息的实时同步和一致。</p><p>服务实例必须在注册表注册和注销。注册和注销有两种不同的方法。一是实例自己注册（更容易实现，但是注册库本身应该具备服务节点心跳检测能力）。另一种是赛用管理服务实例注册的其他系统组件，即第三方注册模式。</p><p>常用的服务注册表例子包括：</p><ul><li>etcd ，一个高可用、分布式、一致性、key-value 方式的存储，被用在分享配置和服务发现中。两个著名的项目使用了它：Kubernetes 和 Cloud Foundry.</li><li>consul ，一个发现和配置服务的工具，为客户端注册和发现服务提供了API，Consul还可以通过执行健康检查决定服务的可用性。</li><li>Apache Zookeeper ，是一个广泛使用、高性能的针对分布式应用的协调服务。 Apache Zookeeper本来是Hadoop的子工程，现在已经是顶级工程了。</li></ul><h1 id="事件驱动的数据管理"><a href="#事件驱动的数据管理" class="headerlink" title="事件驱动的数据管理"></a>事件驱动的数据管理</h1><p>一个单体应用一般只有一个关系型数据库，使用一个关系型数据的优势是应用可以实现ACID。因此，应用可以很简单的开始一个事务，操作（增删改）多条数据，然后提交事务。</p><p>在微服务架构中，每个微服务都有其私有数据库存储，不同的微服务可能使用不同的SQL和NoSQL数据库。这些数据库架构带来便利的同时，也给分布式数据管理带来挑战。一方面是如何实现业务事务，保持多个服务的一致性。另一方面就是如何从多个服务中检索数据，实现查询。</p><p>对于许多应用，解决方案就是事件驱动的架构。在这一架构中，当有显著事件发生时，某个微服务会发布事件，其他微服务则订阅这些事件。当某一微服务接收到事件就可以更新自己的业务实现，实现更多事件被发布。</p><p>事件驱动的优点：它使事务跨多个服务并提供最终一致性。缺点之一在于它的编程模型比ACID事务更加复杂，另外一个劣势就是订阅必须可以检测并忽略重复的事件。另外，事件驱动架构还存在以原子粒度更新数据库并发布事件的问题。</p><h2 id="实现原子化的方案"><a href="#实现原子化的方案" class="headerlink" title="实现原子化的方案"></a>实现原子化的方案</h2><h4 id="采用多步骤本地事务的方法发布事件"><a href="#采用多步骤本地事务的方法发布事件" class="headerlink" title="采用多步骤本地事务的方法发布事件"></a>采用多步骤本地事务的方法发布事件</h4><p>技巧就是有一张event表，更新业务就往event表中插入一条记录，然后提交事务，一个单独应用轮询event表，并根据查询结果来推送。</p><p>这种方案优势是保证了在不使用两段提交前提下事件在每次更新后一定被发布。劣势之一是方案容易出错，程序员必须记得更新后去发布才行，另外一点就是使用nosql时，nosql事务和查询能力有限，实现起来困难。</p><h4 id="挖掘数据库事务日志，然后提交日志实现日志发布"><a href="#挖掘数据库事务日志，然后提交日志实现日志发布" class="headerlink" title="挖掘数据库事务日志，然后提交日志实现日志发布"></a>挖掘数据库事务日志，然后提交日志实现日志发布</h4><p>这种方案的优势在于不使用两段提交的前提下保证了事件一定被发布，事务日志挖掘也可以通过拆分应用业务逻辑事件的发布简化整个应用。劣势是：事务日志每个数据库都不同，甚至同一数据库不同版本也会不同，而且我们很难从低级别的事务日志的更新记录中反推高级别的业务事件。</p><h4 id="使用事件源"><a href="#使用事件源" class="headerlink" title="使用事件源"></a>使用事件源</h4><p>这种方案存储一系列状态变化的事件而不是存储当前实体的状态。一旦业务实体发生变化，一个新的事件就会被添加到事件列表中，由于保存事件是单一操作，本身就是原子性的。</p><p>事件源的优势在于它使得事件发生时可靠的发布事件成为可能，解决了微服务架构中的数据一致性问题。另外一点就是，业务逻辑与交换事件的实体是松耦合的，这使得迁移一个单体应用到微服务架构更加简单</p><p>事件源的劣势子在于，事件数据库对程序员来说很陌生，它仅仅支持主键的方式查询业务实体，必须使用CQRS来实现查询。因此，应用必须处理最终一致性。</p><h1 id="如何重构单体应用到微服务"><a href="#如何重构单体应用到微服务" class="headerlink" title="如何重构单体应用到微服务"></a>如何重构单体应用到微服务</h1><p>从一个现存应用迁移到微服务的过程是应用现代化的一种形式，不应该以从头完全重写的方式把现存应用变为微服务，相反的，应该逐步的把应用重构为一系列的微服务。可以使用三种策略：使用微服务实现新的功能；把表现层从业务逻辑和数据访问组件中拆分出来；把单体应用中的现有模块转化为服务。随着时间推移，微服务的数量将会增长，团队的敏捷性和开发速度也会提升。</p><h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><p>本文大部分内容源自阅读nginx blog上的大神Chris Richardson发布的<a href="https://www.nginx.com/blog/introduction-to-microservices/" target="_blank" rel="noopener">七篇针对微服务的文章</a>，刚好公司最近正在将一个传统应用迁移至微服务，自己阅读理解的同时将笔记分享出来。</p>]]></content>
      
      <categories>
          
          <category> 架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微服务 </tag>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
